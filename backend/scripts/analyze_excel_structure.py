#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∞–ª—å–Ω—ã—Ö Excel —Ñ–∞–π–ª–æ–≤
–í–ê–ñ–ù–û: –ù–µ –∏–∑–º–µ–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –∫–æ–¥ –ø–æ–¥ –Ω–µ—ë
"""
import pandas as pd
import os
import sys
from pathlib import Path
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

DATA_DIR = Path("../data")

def analyze_excel_files():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ Excel —Ñ–∞–π–ª—ã –∏ –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
    
    files_info = {
        "RISK_ANALYSIS_RESULTS.xlsx": None,
        "ML_DATASET_COMPLETE.xlsx": None,
        "crime_analysis_results.xlsx": None,
        "serious_crimes_analysis.xlsx": None,
        "risk_escalation_matrix.xlsx": None
    }
    
    for filename in files_info.keys():
        filepath = DATA_DIR / filename
        if filepath.exists():
            print(f"\nüìÅ –ê–Ω–∞–ª–∏–∑ {filename}:")
            print("=" * 60)
            
            try:
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                excel_file = pd.ExcelFile(filepath)
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª–∏—Å—Ç–∞—Ö
                print(f"–õ–∏—Å—Ç—ã: {excel_file.sheet_names}")
                
                file_data = {
                    'sheets': {},
                    'main_sheet': None,
                    'total_rows': 0
                }
                
                # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
                for sheet in excel_file.sheet_names:
                    df = pd.read_excel(filepath, sheet_name=sheet)
                    print(f"\n  –õ–∏—Å—Ç '{sheet}':")
                    print(f"  - –°—Ç—Ä–æ–∫: {len(df)}")
                    print(f"  - –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
                    print(f"  - –ö–æ–ª–æ–Ω–∫–∏ (–ø–µ—Ä–≤—ã–µ 10): {list(df.columns)[:10]}")
                    
                    sheet_info = {
                        'row_count': len(df),
                        'columns': list(df.columns),
                        'has_iin': False,
                        'has_risk_score': False,
                        'sample_data': {}
                    }
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è
                    if '–ò–ò–ù' in df.columns:
                        print(f"  - ‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –ò–ò–ù")
                        sheet_info['has_iin'] = True
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ò–ò–ù
                        sample_iin = df['–ò–ò–ù'].dropna().iloc[0] if len(df['–ò–ò–ù'].dropna()) > 0 else None
                        print(f"  - –ü—Ä–∏–º–µ—Ä –ò–ò–ù: {sample_iin}")
                        sheet_info['sample_data']['iin'] = str(sample_iin) if sample_iin else None
                        file_data['main_sheet'] = sheet
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–ª–µ–π —Å —Ä–∏—Å–∫-–±–∞–ª–ª–æ–º
                    risk_fields = ['risk_total_risk_score', 'risk_score', 'total_risk_score', 'Risk Score']
                    for risk_field in risk_fields:
                        if risk_field in df.columns:
                            print(f"  - ‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ —Ä–∏—Å–∫–∞: {risk_field}")
                            sheet_info['has_risk_score'] = True
                            sheet_info['risk_field_name'] = risk_field
                            print(f"  - –î–∏–∞–ø–∞–∑–æ–Ω: {df[risk_field].min():.2f} - {df[risk_field].max():.2f}")
                            sheet_info['sample_data']['risk_range'] = {
                                'min': float(df[risk_field].min()),
                                'max': float(df[risk_field].max()),
                                'mean': float(df[risk_field].mean())
                            }
                            break
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                    pattern_fields = ['pattern_type', 'behavior_pattern', 'Pattern']
                    for pattern_field in pattern_fields:
                        if pattern_field in df.columns:
                            print(f"  - ‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {pattern_field}")
                            unique_patterns = df[pattern_field].unique()
                            print(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {unique_patterns[:5]}")
                            sheet_info['sample_data']['patterns'] = list(unique_patterns[:5])
                            break
                    
                    file_data['sheets'][sheet] = sheet_info
                    file_data['total_rows'] += len(df)
                
                files_info[filename] = file_data
                
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
                files_info[filename] = {'error': str(e)}
        else:
            print(f"\n‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {DATA_DIR.absolute()}")
            files_info[filename] = {'error': 'File not found'}
    
    return files_info

def check_critical_constants(files_info):
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
    print("\n" + "=" * 60)
    print("üîç –ü–†–û–í–ï–†–ö–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –ö–û–ù–°–¢–ê–ù–¢")
    print("=" * 60)
    
    # –ò—â–µ–º —Ñ–∞–π–ª —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    main_file = None
    for filename, info in files_info.items():
        if info and info.get('main_sheet'):
            main_file = filename
            break
    
    if main_file:
        filepath = DATA_DIR / main_file
        df = pd.read_excel(filepath, sheet_name=files_info[main_file]['main_sheet'])
        
        total_records = len(df)
        print(f"\nüìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é
        expected_total = 146570
        if abs(total_records - expected_total) < 1000:  # –î–æ–ø—É—Å–∫ 1000 –∑–∞–ø–∏—Å–µ–π
            print(f"‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (~{expected_total:,})")
        else:
            print(f"‚ö†Ô∏è –û—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ ({expected_total:,})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        pattern_fields = ['pattern_type', 'behavior_pattern', 'Pattern']
        for pattern_field in pattern_fields:
            if pattern_field in df.columns:
                pattern_counts = df[pattern_field].value_counts()
                total_with_pattern = pattern_counts.sum()
                
                if 'mixed_unstable' in pattern_counts.index:
                    unstable_count = pattern_counts['mixed_unstable']
                    unstable_percent = (unstable_count / total_with_pattern) * 100
                    print(f"\nüîÑ –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: {unstable_percent:.1f}%")
                    
                    if abs(unstable_percent - 72.7) < 5:  # –î–æ–ø—É—Å–∫ 5%
                        print(f"‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º—ã–º 72.7%")
                    else:
                        print(f"‚ö†Ô∏è –û—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–µ–º—ã—Ö 72.7%")
                break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—Ü–∏–¥–∏–≤–∏—Å—Ç–æ–≤
        if 'total_cases' in df.columns:
            recidivists = df[df['total_cases'] > 1]
            recidivist_count = len(recidivists)
            print(f"\nüë• –†–µ—Ü–∏–¥–∏–≤–∏—Å—Ç–æ–≤: {recidivist_count:,}")
            
            expected_recidivists = 12333
            if abs(recidivist_count - expected_recidivists) < 500:
                print(f"‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (~{expected_recidivists:,})")
            else:
                print(f"‚ö†Ô∏è –û—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ ({expected_recidivists:,})")

if __name__ == "__main__":
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Excel —Ñ–∞–π–ª–æ–≤")
    print("=" * 60)
    
    structure = analyze_excel_files()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    check_critical_constants(structure)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∏–º–ø–æ—Ä—Ç–µ
    output_file = Path('data_structure.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(structure, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\n‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_file.absolute()}")
    print("\nüìã –†–ï–ó–Æ–ú–ï:")
    print("-" * 40)
    
    for filename, info in structure.items():
        if info and not info.get('error'):
            print(f"‚úÖ {filename}: {info.get('total_rows', 0):,} –∑–∞–ø–∏—Å–µ–π")
        elif info and info.get('error'):
            print(f"‚ùå {filename}: {info['error']}")
        else:
            print(f"‚ùå {filename}: –ù–µ –Ω–∞–π–¥–µ–Ω")