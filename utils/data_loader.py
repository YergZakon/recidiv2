"""
–ú–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Ä–∞–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
import streamlit as st
from typing import Dict, Optional, Tuple

# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞–Ω–Ω—ã–º–∏
DATA_DIR = "data"

# –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
DATA_FILES = {
    'risk_analysis': 'RISK_ANALYSIS_RESULTS.xlsx',
    'ml_dataset': 'ML_DATASET_COMPLETE.xlsx',
    'crime_analysis': 'crime_analysis_results.xlsx',
    'serious_crimes': 'serious_crimes_analysis.xlsx',
    'risk_matrix': 'risk_escalation_matrix.xlsx'
}

@st.cache_data(ttl=3600)  # –ö—ç—à –Ω–∞ 1 —á–∞—Å
def load_all_data() -> Dict[str, pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å DataFrame
    """
    data_dict = {}
    
    for key, filename in DATA_FILES.items():
        filepath = os.path.join(DATA_DIR, filename)
        
        try:
            if os.path.exists(filepath):
                # –ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞
                if key == 'crime_analysis':
                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Å—Ç–æ–≤
                    excel_file = pd.ExcelFile(filepath)
                    data_dict[key] = {}
                    for sheet in excel_file.sheet_names:
                        data_dict[key][sheet] = pd.read_excel(excel_file, sheet_name=sheet)
                else:
                    data_dict[key] = pd.read_excel(filepath)
                
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω {filename}")
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                data_dict[key] = None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
            data_dict[key] = None
    
    return data_dict

@st.cache_data
def get_risk_data() -> Optional[pd.DataFrame]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ä–∏—Å–∫–∞—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
    """
    data = load_all_data()
    risk_df = data.get('risk_analysis')
    
    if risk_df is not None:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        required_columns = ['–ò–ò–ù', 'risk_total_risk_score', 'pattern_type']
        
        for col in required_columns:
            if col not in risk_df.columns:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ {col}")
                return None
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        risk_df = risk_df.dropna(subset=['–ò–ò–ù'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∏—Å–∫–∞ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if 'risk_category' not in risk_df.columns:
            risk_df['risk_category'] = risk_df['risk_total_risk_score'].apply(
                lambda x: get_risk_category(x)
            )
        
        return risk_df
    
    return None

@st.cache_data
def get_crime_statistics() -> Dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è–º –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
    """
    # –ë–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    stats = {
        'total_violations': 146570,
        'total_recidivists': 12333,
        'preventable_percent': 97.0,
        'unstable_pattern_percent': 72.7,
        'admin_to_theft_count': 6465,
        'crime_windows': {
            '–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ': {'days': 109, 'preventable': 82.3},
            '–ö—Ä–∞–∂–∞': {'days': 146, 'preventable': 87.3},
            '–£–±–∏–π—Å—Ç–≤–æ': {'days': 143, 'preventable': 97.0},
            '–í—ã–º–æ–≥–∞—Ç–µ–ª—å—Å—Ç–≤–æ': {'days': 144, 'preventable': 100.7},
            '–ì—Ä–∞–±–µ–∂': {'days': 148, 'preventable': 60.2},
            '–†–∞–∑–±–æ–π': {'days': 150, 'preventable': 20.2},
            '–ò–∑–Ω–∞—Å–∏–ª–æ–≤–∞–Ω–∏–µ': {'days': 157, 'preventable': 65.6}
        }
    }
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    data = load_all_data()
    
    if data.get('crime_analysis') and isinstance(data['crime_analysis'], dict):
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if '–≠—Å–∫–∞–ª–∞—Ü–∏—è' in data['crime_analysis']:
            escalation_df = data['crime_analysis']['–≠—Å–∫–∞–ª–∞—Ü–∏—è']
            if not escalation_df.empty:
                stats['total_escalations'] = len(escalation_df)
                stats['top_escalation'] = escalation_df.iloc[0]['–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ'] if len(escalation_df) > 0 else None
    
    return stats

@st.cache_data
def get_pattern_distribution() -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    """
    risk_df = get_risk_data()
    
    if risk_df is not None and 'pattern_type' in risk_df.columns:
        pattern_counts = risk_df['pattern_type'].value_counts()
        pattern_percent = (pattern_counts / len(risk_df) * 100).round(1)
        
        return pd.DataFrame({
            'pattern': pattern_counts.index,
            'count': pattern_counts.values,
            'percent': pattern_percent.values
        })
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    return pd.DataFrame({
        'pattern': ['mixed_unstable', 'chronic_criminal', 'escalating', 'deescalating', 'single'],
        'count': [8968, 1678, 863, 703, 121],
        'percent': [72.7, 13.6, 7.0, 5.7, 1.0]
    })

def get_risk_category(risk_score: float) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ä–∏—Å–∫–∞ –ø–æ –±–∞–ª–ª—É
    """
    if risk_score >= 7:
        return "üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
    elif risk_score >= 5:
        return "üü° –í—ã—Å–æ–∫–∏–π"
    elif risk_score >= 3:
        return "üü† –°—Ä–µ–¥–Ω–∏–π"
    else:
        return "üü¢ –ù–∏–∑–∫–∏–π"

def validate_iin(iin: str) -> Tuple[bool, str]:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –ò–ò–ù —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –æ–± –æ—à–∏–±–∫–∞—Ö
    """
    if not iin:
        return False, "–ò–ò–ù –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥–µ—Ñ–∏—Å—ã
    clean_iin = iin.replace('-', '').replace(' ', '')
    
    if len(clean_iin) != 12:
        return False, f"–ò–ò–ù –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 12 —Ü–∏—Ñ—Ä (–≤–≤–µ–¥–µ–Ω–æ: {len(clean_iin)})"
    
    if not clean_iin.isdigit():
        return False, "–ò–ò–ù –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º—É –†–ö
    
    return True, clean_iin

def search_person_by_iin(iin: str) -> Optional[pd.Series]:
    """
    –ü–æ–∏—Å–∫ —á–µ–ª–æ–≤–µ–∫–∞ –ø–æ –ò–ò–ù –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    """
    is_valid, clean_iin = validate_iin(iin)
    
    if not is_valid:
        return None
    
    risk_df = get_risk_data()
    
    if risk_df is not None:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ò–ò–ù –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø–æ–∏—Å–∫–∞
        risk_df_copy = risk_df.copy()
        risk_df_copy['–ò–ò–ù'] = risk_df_copy['–ò–ò–ù'].astype(str)
        
        # –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
        exact_match = risk_df_copy[risk_df_copy['–ò–ò–ù'] == clean_iin]
        if not exact_match.empty:
            return exact_match.iloc[0]
        
        # –ü–æ–∏—Å–∫ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º 4 —Ü–∏—Ñ—Ä–∞–º
        last_4 = clean_iin[-4:]
        partial_match = risk_df_copy[risk_df_copy['–ò–ò–ù'].str.endswith(last_4)]
        if not partial_match.empty:
            return partial_match.iloc[0]
    
    return None

@st.cache_data
def get_escalation_patterns() -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –∞–¥–º–∏–Ω -> —É–≥–æ–ª–æ–≤–∫–∞
    """
    data = load_all_data()
    
    if data.get('crime_analysis') and isinstance(data['crime_analysis'], dict):
        if '–≠—Å–∫–∞–ª–∞—Ü–∏—è' in data['crime_analysis']:
            return data['crime_analysis']['–≠—Å–∫–∞–ª–∞—Ü–∏—è']
    
    # –î–µ–º–æ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
    return pd.DataFrame({
        '–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ': ['–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏–µ'] * 5,
        '–£–≥–æ–ª–æ–≤–Ω–æ–µ': ['–ö—Ä–∞–∂–∞', '–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ', '–ì—Ä–∞–±–µ–∂', '–ü–æ–±–æ–∏', '–ù–∞—Ä–∫–æ—Ç–∏–∫–∏'],
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤': [6465, 1968, 771, 587, 645]
    })

@st.cache_data
def calculate_statistics_summary() -> Dict:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
    """
    risk_df = get_risk_data()
    stats = get_crime_statistics()
    
    summary = {
        'total_people': len(risk_df) if risk_df is not None else stats['total_recidivists'],
        'critical_risk': 0,
        'high_risk': 0,
        'active_cases': 0,
        'prevented_estimate': 0
    }
    
    if risk_df is not None:
        # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ä–∏—Å–∫–∞
        if 'risk_category' in risk_df.columns:
            summary['critical_risk'] = len(risk_df[risk_df['risk_category'] == "üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"])
            summary['high_risk'] = len(risk_df[risk_df['risk_category'] == "üü° –í—ã—Å–æ–∫–∏–π"])
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–ª—É—á–∞–∏ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ < 365 –¥–Ω–µ–π)
        if 'last_violation_date' in risk_df.columns:
            risk_df['last_violation_date'] = pd.to_datetime(risk_df['last_violation_date'])
            active_mask = (datetime.now() - risk_df['last_violation_date']).dt.days < 365
            summary['active_cases'] = active_mask.sum()
        
        # –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π
        prevention_rate = stats['preventable_percent'] / 100
        summary['prevented_estimate'] = int(summary['critical_risk'] * prevention_rate)
    
    return summary

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞–º–∏
def parse_date(date_str):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞—Ç
    """
    if pd.isna(date_str):
        return None
    
    date_str = str(date_str).strip()
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    for fmt in ['%Y-%m-%d', '%d.%m.%Y', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S']:
        try:
            return datetime.strptime(date_str, fmt)
        except:
            continue
    
    try:
        return pd.to_datetime(date_str)
    except:
        return None

def days_between(date1, date2):
    """
    –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏
    """
    if pd.isna(date1) or pd.isna(date2):
        return None
    
    try:
        return abs((date2 - date1).days)
    except:
        return None